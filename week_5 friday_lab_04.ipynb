{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### WEEK 5: FRIDAY LAB 04\n",
    "\n",
    "Determine which of the variables in your team dataset depend on other variables; that is, which independent variables can be used to predict values for the dependent variable most effectively.\n",
    "\n",
    "1. Select one dependent variable in the dataset. This will be your target variable for the remainder of this lab. Explain how and why you have selected that particular target variable in no less than 3 sentences.\n",
    "\n",
    "2. Determine what correlations there are among independent variables (= predictors) in the dataset by setting up a correlation table.  Explain in at least 2 sentences what correlations your analysis is showing and if any predictor variables appear to be correlated to one another\n",
    "\n",
    "3. Determine which independent variable in the dataset is the most important overall predictor for your chosen dependent (target) variable, then build a simple linear regression based on this predictor and evaluate the quality of your model. Explain why (or why not) it is acceptable to use this model to predict future values of your dependent variable.\n",
    "\n",
    "4. Run a basic multiple regression and review the p-values for each variable. If any variables have p-values > 0.05, remove them because they are not statistically significant. Rerun the multiple regression until you can see which of the variables in your dataset should be combined to produce an optimal model. Then build and run your multiple regression model and test its quality. Explain how this model improves the output of the simple linear regression you ran previously.\n",
    "\n",
    "5. Transform your dependent variable from question 1 into a binary shape. Build and run a logistic regression model and explain in AT LEAST two sentences how your output improves on the simple and multiple regression. Is the logistic model better or not as good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8949</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29725</td>\n",
       "      <td>city_40</td>\n",
       "      <td>0.776</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11561</td>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>Full time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33241</td>\n",
       "      <td>city_115</td>\n",
       "      <td>0.789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Business Degree</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>never</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666</td>\n",
       "      <td>city_162</td>\n",
       "      <td>0.767</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id      city  city_development_index gender  \\\n",
       "0         8949  city_103                   0.920   Male   \n",
       "1        29725   city_40                   0.776   Male   \n",
       "2        11561   city_21                   0.624    NaN   \n",
       "3        33241  city_115                   0.789    NaN   \n",
       "4          666  city_162                   0.767   Male   \n",
       "\n",
       "       relevent_experience enrolled_university education_level  \\\n",
       "0  Has relevent experience       no_enrollment        Graduate   \n",
       "1   No relevent experience       no_enrollment        Graduate   \n",
       "2   No relevent experience    Full time course        Graduate   \n",
       "3   No relevent experience                 NaN        Graduate   \n",
       "4  Has relevent experience       no_enrollment         Masters   \n",
       "\n",
       "  major_discipline experience company_size    company_type last_new_job  \\\n",
       "0             STEM        >20          NaN             NaN            1   \n",
       "1             STEM         15        50-99         Pvt Ltd           >4   \n",
       "2             STEM          5          NaN             NaN        never   \n",
       "3  Business Degree         <1          NaN         Pvt Ltd        never   \n",
       "4             STEM        >20        50-99  Funded Startup            4   \n",
       "\n",
       "   training_hours  target  \n",
       "0              36     1.0  \n",
       "1              47     0.0  \n",
       "2              83     0.0  \n",
       "3              52     1.0  \n",
       "4               8     0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "#Reading the train HR Analytics: Job Change of Data Scientists dataframe\n",
    "train = pd.read_csv('Job Change/aug_train.csv')\n",
    "\n",
    "\n",
    "#Verifying that we can see the data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id                 int64\n",
       "city                       object\n",
       "city_development_index    float64\n",
       "gender                     object\n",
       "relevent_experience        object\n",
       "enrolled_university        object\n",
       "education_level            object\n",
       "major_discipline           object\n",
       "experience                 object\n",
       "company_size               object\n",
       "company_type               object\n",
       "last_new_job               object\n",
       "training_hours              int64\n",
       "target                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select one dependent variable in the dataset. This will be your target variable for the remainder of this lab. Explain how and why you have selected that particular target variable in no less than 3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Selected dependent variable is the target. This is because in the dataset it tells us the target employees who either wish to change their job or not. It will show us who is likely to wish to change their jobs and predict the employees who will likely wish to change their jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Determine what correlations there are among independent variables (= predictors) in the dataset by setting up a correlation table.  Explain in at least 2 sentences what correlations your analysis is showing and if any predictor variables appear to be correlated to one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>enrollee_id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040455</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.049475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_development_index</th>\n",
       "      <td>-0.040455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>-0.341665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_hours</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.049475</td>\n",
       "      <td>-0.341665</td>\n",
       "      <td>-0.021577</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        enrollee_id  city_development_index  training_hours  \\\n",
       "enrollee_id                1.000000               -0.040455        0.000998   \n",
       "city_development_index    -0.040455                1.000000        0.001920   \n",
       "training_hours             0.000998                0.001920        1.000000   \n",
       "target                     0.049475               -0.341665       -0.021577   \n",
       "\n",
       "                          target  \n",
       "enrollee_id             0.049475  \n",
       "city_development_index -0.341665  \n",
       "training_hours         -0.021577  \n",
       "target                  1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correlation\n",
    "train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enrollee id has the best correlation to Target. The enrollee id has the only positive correlation with target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Determine which independent variable in the dataset is the most important overall predictor for your chosen dependent (target) variable, then build a simple linear regression based on this predictor and evaluate the quality of your model. Explain why (or why not) it is acceptable to use this model to predict future values of your dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train['enrollee_id'], train['target'], alpha=0.5)\n",
    "plt.title('Scatter plot training_hours vs. enrollee_id')\n",
    "plt.xlabel('enrollee_id')\n",
    "plt.ylabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train['city_development_index'], train['target'], alpha=0.5)\n",
    "plt.title('Scatter plot training_hours vs. city_development_index')\n",
    "plt.xlabel('enrollee_id')\n",
    "plt.ylabel('city_development_index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing both scatter points  the higher correlating predictor city_development_index is more important to the target (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.117\n",
      "Model:                            OLS   Adj. R-squared:                  0.117\n",
      "Method:                 Least Squares   F-statistic:                     2532.\n",
      "Date:                Fri, 11 Feb 2022   Prob (F-statistic):               0.00\n",
      "Time:                        10:13:54   Log-Likelihood:                -9943.3\n",
      "No. Observations:               19158   AIC:                         1.989e+04\n",
      "Df Residuals:                   19156   BIC:                         1.991e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.2425      0.020     62.263      0.000       1.203       1.282\n",
      "city_development_index    -1.1983      0.024    -50.316      0.000      -1.245      -1.152\n",
      "==============================================================================\n",
      "Omnibus:                     2419.833   Durbin-Watson:                   1.977\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3421.925\n",
      "Skew:                           1.029   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.772   Cond. No.                         13.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = train['city_development_index']\n",
    "y = train['target']\n",
    "X = sm.add_constant(X)\n",
    "train.mod1 = sm.OLS(y, X).fit()  ## sm.OLS(output, i.e. dependent variable, input, i.e. independent variable)\n",
    "train.mod1_summary = train.mod1.summary()\n",
    "print(train.mod1_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " it is not acceptable to use this model to predict future values of target because R squared variation is 11%. The p value is 0.000 this however shows they are dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run a basic multiple regression and review the p-values for each variable. If any variables have p-values > 0.05, remove them because they are not statistically significant. Rerun the multiple regression until you can see which of the variables in your dataset should be combined to produce an optimal model. Then build and run your multiple regression model and test its quality. Explain how this model improves the output of the simple linear regression you ran previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id                 int64\n",
       "city                       object\n",
       "city_development_index    float64\n",
       "gender                     object\n",
       "relevent_experience        object\n",
       "enrolled_university        object\n",
       "education_level            object\n",
       "major_discipline           object\n",
       "experience                 object\n",
       "company_size               object\n",
       "company_type               object\n",
       "last_new_job               object\n",
       "training_hours              int64\n",
       "target                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8949</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29725</td>\n",
       "      <td>1</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11561</td>\n",
       "      <td>2</td>\n",
       "      <td>0.624</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33241</td>\n",
       "      <td>3</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666</td>\n",
       "      <td>4</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>7386</td>\n",
       "      <td>35</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>31398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19155</th>\n",
       "      <td>24576</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19156</th>\n",
       "      <td>5756</td>\n",
       "      <td>33</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>23834</td>\n",
       "      <td>13</td>\n",
       "      <td>0.855</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19158 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       enrollee_id  city  city_development_index  gender  relevent_experience  \\\n",
       "0             8949     0                   0.920       0                    0   \n",
       "1            29725     1                   0.776       0                    1   \n",
       "2            11561     2                   0.624      -1                    1   \n",
       "3            33241     3                   0.789      -1                    1   \n",
       "4              666     4                   0.767       0                    0   \n",
       "...            ...   ...                     ...     ...                  ...   \n",
       "19153         7386    35                   0.878       0                    1   \n",
       "19154        31398     0                   0.920       0                    0   \n",
       "19155        24576     0                   0.920       0                    0   \n",
       "19156         5756    33                   0.802       0                    0   \n",
       "19157        23834    13                   0.855      -1                    1   \n",
       "\n",
       "       enrolled_university  education_level  major_discipline  experience  \\\n",
       "0                        0                0                 0           0   \n",
       "1                        0                0                 0           1   \n",
       "2                        1                0                 0           2   \n",
       "3                       -1                0                 1           3   \n",
       "4                        0                1                 0           0   \n",
       "...                    ...              ...               ...         ...   \n",
       "19153                    0                0                 3          13   \n",
       "19154                    0                0                 0          13   \n",
       "19155                    0                0                 0           0   \n",
       "19156                    0                2                -1           3   \n",
       "19157                    0                4                -1           8   \n",
       "\n",
       "       company_size  company_type  last_new_job  training_hours  target  \n",
       "0                -1            -1             0              36     1.0  \n",
       "1                 0             0             1              47     0.0  \n",
       "2                -1            -1             2              83     0.0  \n",
       "3                -1             0             2              52     1.0  \n",
       "4                 0             1             3               8     0.0  \n",
       "...             ...           ...           ...             ...     ...  \n",
       "19153            -1            -1             0              42     1.0  \n",
       "19154            -1            -1             3              52     1.0  \n",
       "19155             0             0             3              44     0.0  \n",
       "19156             7             0             5              97     0.0  \n",
       "19157            -1            -1             0             127     0.0  \n",
       "\n",
       "[19158 rows x 14 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic multiple regression \n",
    "\n",
    "# change data type and store only the levels array inplace of the object utilizing pandas factorize\n",
    "\n",
    "train['city'] = pd.factorize(train['city'])[0]\n",
    "train['gender'] = pd.factorize(train['gender'])[0]\n",
    "train['relevent_experience'] = pd.factorize(train['relevent_experience'])[0]\n",
    "train['enrolled_university'] = pd.factorize(train['enrolled_university'])[0]\n",
    "train['education_level'] = pd.factorize(train['education_level'])[0]\n",
    "train['major_discipline'] = pd.factorize(train['major_discipline'])[0]\n",
    "train['experience'] = pd.factorize(train['experience'])[0]\n",
    "train['company_size'] = pd.factorize(train['company_size'])[0]\n",
    "train['company_type'] = pd.factorize(train['company_type'])[0]\n",
    "train['last_new_job'] = pd.factorize(train['last_new_job'])[0]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19158 entries, 0 to 19157\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             19158 non-null  int64  \n",
      " 1   city                    19158 non-null  int32  \n",
      " 2   city_development_index  19158 non-null  float64\n",
      " 3   gender                  19158 non-null  int32  \n",
      " 4   relevent_experience     19158 non-null  int32  \n",
      " 5   enrolled_university     19158 non-null  int32  \n",
      " 6   education_level         19158 non-null  int32  \n",
      " 7   major_discipline        19158 non-null  int32  \n",
      " 8   experience              19158 non-null  int32  \n",
      " 9   company_size            19158 non-null  int32  \n",
      " 10  company_type            19158 non-null  int32  \n",
      " 11  last_new_job            19158 non-null  int32  \n",
      " 12  training_hours          19158 non-null  int64  \n",
      " 13  target                  19158 non-null  float64\n",
      "dtypes: float64(2), int32(10), int64(2)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.170\n",
      "Model:                            OLS   Adj. R-squared:                  0.170\n",
      "Method:                 Least Squares   F-statistic:                     302.2\n",
      "Date:                Fri, 11 Feb 2022   Prob (F-statistic):               0.00\n",
      "Time:                        10:45:20   Log-Likelihood:                -9344.2\n",
      "No. Observations:               19158   AIC:                         1.872e+04\n",
      "Df Residuals:                   19144   BIC:                         1.883e+04\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.3026      0.023     56.960      0.000       1.258       1.347\n",
      "x1          1.019e-06   2.98e-07      3.423      0.001    4.35e-07     1.6e-06\n",
      "x2            -0.0024      0.000    -18.615      0.000      -0.003      -0.002\n",
      "x3            -1.2004      0.024    -49.557      0.000      -1.248      -1.153\n",
      "x4             0.0015      0.005      0.293      0.769      -0.009       0.012\n",
      "x5             0.0771      0.007     11.112      0.000       0.063       0.091\n",
      "x6             0.0276      0.005      5.709      0.000       0.018       0.037\n",
      "x7            -0.0355      0.003    -10.757      0.000      -0.042      -0.029\n",
      "x8             0.0112      0.003      4.112      0.000       0.006       0.016\n",
      "x9          9.096e-05      0.000      0.217      0.828      -0.001       0.001\n",
      "x10           -0.0186      0.001    -16.437      0.000      -0.021      -0.016\n",
      "x11           -0.0125      0.002     -5.860      0.000      -0.017      -0.008\n",
      "x12            0.0004      0.002      0.282      0.778      -0.003       0.003\n",
      "x13           -0.0002   4.74e-05     -3.260      0.001      -0.000   -6.16e-05\n",
      "==============================================================================\n",
      "Omnibus:                     1967.727   Durbin-Watson:                   1.973\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2618.356\n",
      "Skew:                           0.901   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.809   Cond. No.                     2.23e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.23e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X = train.iloc[:, :-1].values\n",
    "y = train.iloc[:, 13].values\n",
    "\n",
    "X = np.append(arr = np.ones((19158, 1)).astype(int), values = X, axis = 1) # We are building our numpy array\n",
    "\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]] # Now we combine all 6 input variables into our first iteration\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit() # Now we set up our regressor function with OLS again as before.\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.170\n",
      "Model:                            OLS   Adj. R-squared:                  0.170\n",
      "Method:                 Least Squares   F-statistic:                     392.9\n",
      "Date:                Fri, 11 Feb 2022   Prob (F-statistic):               0.00\n",
      "Time:                        10:48:58   Log-Likelihood:                -9344.3\n",
      "No. Observations:               19158   AIC:                         1.871e+04\n",
      "Df Residuals:                   19147   BIC:                         1.880e+04\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.3033      0.022     59.928      0.000       1.261       1.346\n",
      "x1          1.022e-06   2.97e-07      3.441      0.001     4.4e-07     1.6e-06\n",
      "x2            -0.0024      0.000    -18.623      0.000      -0.003      -0.002\n",
      "x3            -1.1998      0.024    -50.317      0.000      -1.247      -1.153\n",
      "x4             0.0770      0.007     11.124      0.000       0.063       0.091\n",
      "x5             0.0277      0.005      5.734      0.000       0.018       0.037\n",
      "x6            -0.0355      0.003    -10.761      0.000      -0.042      -0.029\n",
      "x7             0.0112      0.003      4.129      0.000       0.006       0.016\n",
      "x8            -0.0186      0.001    -16.433      0.000      -0.021      -0.016\n",
      "x9            -0.0125      0.002     -5.856      0.000      -0.017      -0.008\n",
      "x10           -0.0002   4.74e-05     -3.258      0.001      -0.000   -6.16e-05\n",
      "==============================================================================\n",
      "Omnibus:                     1968.226   Durbin-Watson:                   1.973\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2619.365\n",
      "Skew:                           0.901   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.810   Cond. No.                     2.16e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.16e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X_opt = X[:, [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 13]] # variables having p-values > 0.05 have been removed\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit() # Now we set up our regressor function with OLS again as before.\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 17.21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_opt, y, test_size = 0.2, random_state = 0) \n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "print('Model accuracy score:', round(regressor.score(X_train,y_train)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy has been improved from the simple linear regression R Squared from 11% to 17%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Transform your dependent variable from question 1 into a binary shape. Build and run a logistic regression model and explain in AT LEAST two sentences how your output improves on the simple and multiple regression. Is the logistic model better or not as good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Dependant variable is already in a binary shape\n",
    "# Logistic regression Model.\n",
    "\n",
    "# Training and Test set\n",
    "dfTrain = train[:17000]\n",
    "dfTest = train[17000:19000]\n",
    "dfCheck = train[19000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.9490e+03,  0.0000e+00,  9.2000e-01, ..., -1.0000e+00,\n",
       "         0.0000e+00,  3.6000e+01],\n",
       "       [ 2.9725e+04,  1.0000e+00,  7.7600e-01, ...,  0.0000e+00,\n",
       "         1.0000e+00,  4.7000e+01],\n",
       "       [ 1.1561e+04,  2.0000e+00,  6.2400e-01, ..., -1.0000e+00,\n",
       "         2.0000e+00,  8.3000e+01],\n",
       "       ...,\n",
       "       [ 2.6174e+04,  3.0000e+01,  8.6600e-01, ...,  0.0000e+00,\n",
       "         2.0000e+00,  1.7000e+01],\n",
       "       [ 2.2248e+04,  0.0000e+00,  9.2000e-01, ...,  3.0000e+00,\n",
       "         4.0000e+00,  1.4000e+01],\n",
       "       [ 1.5934e+04,  1.5000e+01,  9.1000e-01, ...,  0.0000e+00,\n",
       "         0.0000e+00,  6.0000e+01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = np.asarray(dfTrain['target']) # We store target in train_y, but as numpy array\n",
    "train_x = np.asarray(dfTrain.drop('target',1)) # We remove target from the predictors (because it's the output variable)\n",
    "test_y = np.asarray(dfTest['target']) # See the comments above\n",
    "test_x = np.asarray(dfTest.drop('target',1))\n",
    "train_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(train_x, axis=0)\n",
    "std = np.std(train_x, axis=0)\n",
    " \n",
    "train_x = (train_x - means)/std\n",
    "test_x = (test_x - means)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  78.10000000000001 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.score(test_x, test_y)\n",
    "print(\"accuracy = \", accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy compared to linear regression is improved drastically from 17% to 78.10000000000001 %. Compared to linear regression Logistic regression is much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
